{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.predict import predict_spam, load_model   \n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    precision_recall_curve,\n",
    "    classification_report\n",
    ")\n",
    "from src.config import PROCESSED_DATA_DIR, MODELS_DIR\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "from src.modeling.train import FEATURE_COLUMNS\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_PATH = PROCESSED_DATA_DIR / \"test.parquet\"\n",
    "\n",
    "def get_model_path(model_name: str): \n",
    "    MODEL_PATH = MODELS_DIR / f\"{model_name}.pkl\"\n",
    "    if not MODEL_PATH: \n",
    "        raise FileNotFoundError\n",
    "    return MODEL_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = load_model(get_model_path('Logistic_regression'))\n",
    "rf_model = load_model(get_model_path('random_forest'))\n",
    "xg_model = load_model(get_model_path('xg_boosting'))\n",
    "test = pd.read_parquet(TEST_SET_PATH)\n",
    "X_test = test[FEATURE_COLUMNS]\n",
    "y_test = test['label_encoded']\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_xg = xg_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dumb = np.zeros_like(y_test)  # assuming Ham = 0, Spam = 1\n",
    "def class_report_model(y_pred_model): \n",
    "    pr = f\"{precision_score(y_test, y_pred_model, pos_label=1, zero_division=0):.4f}\"\n",
    "    re = f\"{recall_score(y_test, y_pred_model, pos_label=1):.4f}\"\n",
    "    f1 = f\"{f1_score(y_test, y_pred_model, pos_label=1, zero_division=0):.4f}\"\n",
    "    acc = f\"{accuracy_score(y_test, y_pred_model):.4f}\"\n",
    "    return (pr, re, f1, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_repo = class_report_model(y_pred_dumb)\n",
    "lr_repo = class_report_model(y_pred_lr)\n",
    "rf_repo = class_report_model(y_pred_rf)\n",
    "xg_repo = class_report_model(y_pred_xg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather results\n",
    "results = [\n",
    "    [\"MVP Baseline\", \">=0.85\", \">=0.75\", \">=0.80\" , \"-\"],\n",
    "    [\"Dumb Baseline (All Ham)\", dump_repo[0], dump_repo[1], dump_repo[2], dump_repo[3]],\n",
    "    [\"Logistic Regression\", lr_repo[0], lr_repo[1], lr_repo[2] ,lr_repo[3]],\n",
    "    [\"Random Forest\", rf_repo[0], rf_repo[1], rf_repo[2],rf_repo[3]],\n",
    "    [\"XGboosting\", xg_repo[0],  xg_repo[1],  xg_repo[2],  xg_repo[3]],\n",
    "]\n",
    "\n",
    "print(tabulate(results, headers=[\"Model\", \"Precision\", \"Recall\", \"F1-Score\",\"Accuracy\"], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_dump = confusion_matrix(y_test, y_pred_dumb)\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_xg = confusion_matrix(y_test, y_pred_xg)\n",
    "plt.figure(figsize=(6, 4))\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cm_dump, ax=axes[0,0],annot=True ,fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], \n",
    "            yticklabels=['Ham', 'Spam'])\n",
    "axes[0, 0].set_title('Dump model Confusion Matrix')\n",
    "axes[0, 0].set_ylabel('True Label')\n",
    "axes[0, 0].set_xlabel('Predicted Label')\n",
    "sns.heatmap(cm_lr, ax=axes[0,1],annot=True ,fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], \n",
    "            yticklabels=['Ham', 'Spam'])\n",
    "\n",
    "axes[0, 1].set_title('Logistic Regression Confusion Matrix')\n",
    "axes[0, 1].set_ylabel('True Label')\n",
    "axes[0, 1].set_xlabel('Predicted Label')\n",
    "sns.heatmap(cm_rf, ax=axes[1,0],annot=True ,fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], \n",
    "            yticklabels=['Ham', 'Spam'])\n",
    "\n",
    "axes[1, 0].set_title('Random Forest Confusion Matrix')\n",
    "axes[1, 0].set_ylabel('True Label')\n",
    "axes[1, 0].set_xlabel('Predicted Label')\n",
    "sns.heatmap(cm_xg, ax=axes[1,1],annot=True ,fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], \n",
    "            yticklabels=['Ham', 'Spam'])\n",
    "\n",
    "axes[1, 1].set_title('XGBoosting Confusion Matrix')\n",
    "axes[1, 1].set_ylabel('True Label')\n",
    "axes[1, 1].set_xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature coefficients \n",
    "importance = pd.DataFrame({\n",
    "    'feature': FEATURE_COLUMNS, \n",
    "    'coefficient': lr_model.coef_[0]\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "\n",
    "print(\"\\nüîç FEATURE IMPORTANCE (Logistic Regression Coefficients):\")\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=importance, y='feature', x='coefficient', hue='feature', palette='viridis')\n",
    "plt.title('Feature Importance (Coefficients)')\n",
    "plt.xlabel('Coefficient (positive = spammy)')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms-binary-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
